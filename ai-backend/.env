# Server Configuration
API_PORT=5050
HOST=0.0.0.0
LOG_LEVEL=INFO

# Dynamic Port Allocation
AUTO_FIND_PORT=true
PORT_RANGE_START=5050
PORT_RANGE_END=5100

# CORS Settings
ALLOW_ORIGINS=*

# Authentication
API_KEY=daf2bce30b362d2d6ae42d80865c08eefa0e7929cb255f88101fbeb053ba48ec
AUTH_REQUIRED=false
METRICS_PUBLIC=true

# Prometheus Metrics
PROMETHEUS_ENABLE=true

# Rate Limiting
RATE_LIMIT_PER_MIN=60
USE_REDIS=false
REDIS_URL=redis://localhost:6379

# vLLM Configuration
DEFAULT_MODEL_KEY=tiny
DEFAULT_MODEL_NAME=TinyLlama/TinyLlama-1.1B-Chat-v1.0
VLLM_BASE_URL=http://localhost:8000
MODEL_ROUTE_tiny=http://localhost:8000/v1

# Allowed Models
ALLOWED_MODELS=

# HTTP Timeouts
CONNECT_TIMEOUT_SECONDS=10
READ_TIMEOUT_SECONDS=60
WRITE_TIMEOUT_SECONDS=60
TOTAL_TIMEOUT_SECONDS=180

# Database
DATABASE_URL=sqlite:///C:/Users/trees/ai-backend-gateway-venv/ai_backend.db
DB_ECHO=false

# Development Settings
DEBUG=false
RELOAD=true
